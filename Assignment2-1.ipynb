{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__DSC 478__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Jonathan Lynch__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assignment 2 - Part 1:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## K-Nearest-Neighbor (KNN) classification on Newsgroups Dataset:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Import libraries and read in necessary files:__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/jonathanlynch/Desktop/DSC 478\n"
     ]
    }
   ],
   "source": [
    "## load libraries\n",
    "import sys\n",
    "from numpy import *\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import operator\n",
    "\n",
    "%cd \"/Users/jonathanlynch/Desktop/DSC 478\"\n",
    "\n",
    "# import train & test matrices:\n",
    "train_matrix = pd.read_csv('trainMatrixModified.txt', sep = \"\\t\", header = None)\n",
    "test_matrix = pd.read_csv('testMatrixModified.txt', sep = \"\\t\", header = None)\n",
    "\n",
    "\n",
    "# import train and test class labels:\n",
    "train_labels = pd.read_csv('trainClasses.txt', sep = \"\\t\", header = None)\n",
    "test_labels = pd.read_csv('testClasses.txt', sep = \"\\t\", header = None)\n",
    "\n",
    "\n",
    "# import terms:\n",
    "terms = pd.read_csv('modifiedterms.txt', header = None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Transpose train_matrix & test_matrix:__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_matrix_T = train_matrix.transpose()\n",
    "test_matrix_T = test_matrix.transpose()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Convert to arrays:__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_matrix_T = np.array(train_matrix_T)\n",
    "test_matrix_T = np.array(test_matrix_T)\n",
    "\n",
    "train_labels = np.asarray(train_labels[1])\n",
    "test_labels = np.asarray(test_labels[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1-A: Create KNN classifier function (inputs: instance, training data, training labels, K, distance measure):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def knn_classify(x, D, L, K, measure):\n",
    "    if measure == 0:                        # euclidean dist\n",
    "        dists = sqrt(((D - x)**2).sum(axis=1))\n",
    "    elif measure == 1:                      # cosine dist\n",
    "        D_norm = array([linalg.norm(D[i]) for i in range(len(D))])\n",
    "        x_norm = linalg.norm(x)\n",
    "        cosines = np.dot(D,x)/(D_norm * x_norm)\n",
    "        dists = 1 - cosines\n",
    "    idx = np.argsort(dists)\n",
    "    count={}          \n",
    "    for i in range(K):\n",
    "        vote = L[idx[i]]\n",
    "        count[vote] = count.get(vote,0) + 1\n",
    "    sortedClass = sorted(count.items(), key = operator.itemgetter(1), reverse = True)\n",
    "    return sortedClass[0][0], idx[:K]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Look at two examples of the class prediction & k nearest neighbor indices with k=5 (Euclidean distance & Cosine similarity):__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Euclidean Distance:\n",
      "class prediction: 1\n",
      "k nearest neighbor indices: [685 628 703 266 510]\n",
      "\n",
      "Cosine Similarity:\n",
      "class prediction: 1\n",
      "k nearest neighbor indices: [685 628 667 152 427]\n"
     ]
    }
   ],
   "source": [
    "class_prediction, neigh_indices = knn_classify(test_matrix_T[0], train_matrix_T, train_labels, 5, 0) # Euclidean dist\n",
    "print('Euclidean Distance:')\n",
    "print('class prediction: ' + str(class_prediction))\n",
    "print('k nearest neighbor indices: ' + str(neigh_indices))\n",
    "print()\n",
    "class_prediction2, neigh_indices2 = knn_classify(test_matrix_T[0], train_matrix_T, train_labels, 5, 1) # Cosine similarity\n",
    "print('Cosine Similarity:')\n",
    "print('class prediction: ' + str(class_prediction2))\n",
    "print('k nearest neighbor indices: ' + str(neigh_indices2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1-B: Create a function to compute the classification accuracy over all the test data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy(T, x, D, L, K, measure):\n",
    "    num_labels = len(T)\n",
    "    errors = 0.0\n",
    "    for i in range(num_labels):\n",
    "        class_prediction, neigh_indices = knn_classify(x[i,:], D, L, K, measure)\n",
    "        if (class_prediction != T[i]): \n",
    "            errors += 1.0\n",
    "    error_rate = errors/float(num_labels)\n",
    "    return (1-error_rate)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Check the accuracy of the knn classifier over the entire test dataset for both distance measures (with k=5):__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The accuracy rate with Euclidean distance is: 0.815\n",
      "The accuracy rate with Cosine similarity is: 0.97\n"
     ]
    }
   ],
   "source": [
    "result1 = accuracy(test_labels, test_matrix_T, train_matrix_T, train_labels, 5, 0)\n",
    "print('The accuracy rate with Euclidean distance is: ' + str(result1))\n",
    "\n",
    "result2 = accuracy(test_labels, test_matrix_T, train_matrix_T, train_labels, 5, 1)\n",
    "print('The accuracy rate with Cosine similarity is: ' + str(result2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1-C: Run accuracy function on a range of values for K and both distance measures in order to compare differences in accuracy rates:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Differences in Accuracy:\n",
      "\n",
      " K  Euclid  Cosine\n",
      " 1   0.78    0.98\n",
      " 2   0.78    0.98\n",
      " 3   0.81    0.97\n",
      " 4   0.81    0.98\n",
      " 5   0.81    0.97\n",
      " 6   0.83    0.98\n",
      " 7   0.77    0.98\n",
      " 8   0.80    0.98\n",
      " 9   0.75    0.97\n",
      "10   0.85    0.98\n",
      "11   0.80    0.98\n",
      "12   0.84    0.97\n",
      "13   0.78    0.98\n",
      "14   0.81    0.98\n",
      "15   0.79    0.98\n",
      "16   0.80    0.98\n",
      "17   0.76    0.97\n",
      "18   0.79    0.97\n",
      "19   0.74    0.97\n",
      "20   0.77    0.97\n"
     ]
    }
   ],
   "source": [
    "accuracies = np.zeros((20,3), dtype=float)\n",
    "for i in range(20):\n",
    "    accuracy_Euc = accuracy(test_labels, test_matrix_T, train_matrix_T, train_labels, i+1, 0)\n",
    "    accuracy_Cos = accuracy(test_labels, test_matrix_T, train_matrix_T, train_labels, i+1, 1)\n",
    "    accuracies[i] = [i+1, accuracy_Euc, accuracy_Cos]\n",
    "    \n",
    "print('Differences in Accuracy:\\n')\n",
    "print(\" K  Euclid  Cosine\")\n",
    "for row in accuracies:\n",
    "    print(\"%2.0f   %.2f    %.2f\" % (row[0], row[1], row[2]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1-D: Convert term weights to TFxIDF weights and rerun evaluation on range of values for K with both distance measures:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__converting train_matrix to TFxIDF weights:__ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "TD = train_matrix                        # renaming train_matrix\n",
    "DF = pd.DataFrame([(TD!=0).sum(1)]).T    # doc counts for each term\n",
    "NDocs = TD.shape[1]                      # num of docs\n",
    "NMatrix=np.ones(np.shape(TD), dtype=float)*NDocs   # create matrix  with all entries = num docs\n",
    "IDF = np.log2(np.divide(NMatrix, np.array(DF)))    # convert each entry to IDF value\n",
    "TD_tfidf = TD * IDF                      # compute the TFxIDF values for each document-term entry\n",
    "DT_tfidf = TD_tfidf.T                    # transposing to doc x term matrix\n",
    "DT_array = np.array(DT_tfidf)            # converting to array"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__converting test_matrix to TFxIDF weights:__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "TD1 = test_matrix                        # renaming test_matrix\n",
    "DF1 = pd.DataFrame([(TD1!=0).sum(1)]).T    # doc counts for each term\n",
    "DF1.replace(0,1,inplace=True)              # replace all zeros with ones so don't get an error when trying to divide by a zero when computing IDF1\n",
    "NDocs1 = TD1.shape[1]                      # num of docs\n",
    "NMatrix1=np.ones(np.shape(TD1), dtype=float)*NDocs1   # create matrix  with all entries = num docs\n",
    "IDF1 = np.log2(np.divide(NMatrix1, np.array(DF1)))    # convert each entry to IDF value\n",
    "TD_tfidf1 = TD1 * IDF1                      # compute the TFxIDF values for each document-term entry\n",
    "DT_tfidf1 = TD_tfidf1.T                    # transposing to doc x term matrix\n",
    "DT_array1 = np.array(DT_tfidf1)            # converting to array"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Re-run accuracy function with test and training sets converted to TFxIDF weights on a range of values for K:__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Differences in Accuracy with TFxIDF weights:\n",
      "\n",
      " K  Euclid  Cosine\n",
      " 1   0.71    0.95\n",
      " 2   0.71    0.95\n",
      " 3   0.73    0.96\n",
      " 4   0.71    0.97\n",
      " 5   0.80    0.97\n",
      " 6   0.82    0.97\n",
      " 7   0.71    0.98\n",
      " 8   0.76    0.99\n",
      " 9   0.66    0.98\n",
      "10   0.75    0.99\n",
      "11   0.69    0.99\n",
      "12   0.72    0.99\n",
      "13   0.65    0.99\n",
      "14   0.66    0.99\n",
      "15   0.61    0.99\n",
      "16   0.67    0.99\n",
      "17   0.61    0.99\n",
      "18   0.67    0.99\n",
      "19   0.61    0.99\n",
      "20   0.67    0.99\n"
     ]
    }
   ],
   "source": [
    "TFIDF_accuracies = np.zeros((20,3), dtype=float)\n",
    "for i in range(20):\n",
    "    accuracy_Euc = accuracy(test_labels, DT_array1, DT_array, train_labels, i+1, 0)\n",
    "    accuracy_Cos = accuracy(test_labels, DT_array1, DT_array, train_labels, i+1, 1)\n",
    "    TFIDF_accuracies[i] = [i+1, accuracy_Euc, accuracy_Cos]\n",
    "    \n",
    "print('Differences in Accuracy with TFxIDF weights:\\n')\n",
    "print(\" K  Euclid  Cosine\")\n",
    "for row in TFIDF_accuracies:\n",
    "    print(\"%2.0f   %.2f    %.2f\" % (row[0], row[1], row[2]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Comparing the accuracy results of the training and test sets converted to TFxIDF weights with the accuracy results of the training and test sets using raw term frequencies, the Euclidean distance measure performed worse (less accuracy) across all values of K with the TFxIDF weighted training/test sets.  Using the Cosine similarity measure, the accuracy results were relatively good for both TFxIDF weighted training/test sets and training/test sets with raw term frequencies.  It looks like for lower values of K, using the raw term frequencies for the training/test sets performed slightly better, and for higher values of K, training/test sets converted to TFxIDF weights were slightly more accurate for the Cosine similarity measure."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1-E: Create a new classifier based on the Rocchio Method adapted for text categorization:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Create Rocchio training function that returns prototype vectors for each class:__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_labels = pd.read_csv('trainClasses.txt', sep = \"\\t\", header = None)\n",
    "DT_TFIDF = TD_tfidf.T\n",
    "\n",
    "def rocchio_train(DT_TFIDF, train_labels):\n",
    "    hockey_idx = train_labels[(train_labels[1] == 1)]\n",
    "    windows_idx = train_labels[(train_labels[1] == 0)]  \n",
    "    hindex = hockey_idx.index \n",
    "    windex = windows_idx.index\n",
    "    windows_proto_DF = DT_TFIDF[DT_TFIDF.index.isin(windex)]\n",
    "    windows_proto_vector = windows_proto_DF.sum()\n",
    "    hockey_proto_DF = DT_TFIDF[DT_TFIDF.index.isin(hindex)]\n",
    "    hockey_proto_vector = hockey_proto_DF.sum()\n",
    "    return windows_proto_vector, hockey_proto_vector"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Create Rocchio classifier function that returns class prediction & similarity values to each category prototype:__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rocchio_classifier(windows_proto_vector,hockey_proto_vector,ins):\n",
    "    x = windows_proto_vector\n",
    "    y = hockey_proto_vector\n",
    "   \n",
    "    # compute the cosine similarity between ins and both x and y\n",
    "    x_norm = np.linalg.norm(x)\n",
    "    y_norm = np.linalg.norm(y) \n",
    "    ins_norm = np.linalg.norm(ins)    \n",
    "    \n",
    "    # x (windows)\n",
    "    xsim = np.dot(x,ins)/(x_norm * ins_norm)\n",
    "    xdist = 1 - xsim\n",
    "    \n",
    "    # y (hockey)\n",
    "    ysim = np.dot(y,ins)/(y_norm * ins_norm)\n",
    "    ydist = 1 - ysim\n",
    "    \n",
    "    # return the predicted class\n",
    "    if xdist < ydist:\n",
    "        pred_class = 0\n",
    "    elif ydist < xdist:\n",
    "        pred_class = 1\n",
    "\n",
    "\n",
    "    # return the similarity values of the instance to each of the category prototypes & class prediction\n",
    "    return xsim, ysim, pred_class"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Create function to compute the classification accuracy over all the test data using Rocchio method:__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rocchio_accuracy(T, ins, D, L):\n",
    "    num_labels = len(T)\n",
    "    errors = 0.0\n",
    "    windows_proto_vector, hockey_proto_vector = rocchio_train(DT_TFIDF, train_labels)\n",
    "    for i in range(num_labels):\n",
    "        xsim, ysim, pred_class = rocchio_classifier(windows_proto_vector,hockey_proto_vector,test_matrix_T[i,:])\n",
    "        if (pred_class != T[i]): \n",
    "            errors += 1.0\n",
    "    error_rate = errors/float(num_labels)\n",
    "    return (1-error_rate)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Compute the Rocchio classification accuracy using the test instances and compare with previous results:__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The accuracy rate with the Rocchio Method is: 0.98\n"
     ]
    }
   ],
   "source": [
    "result_rocchio = rocchio_accuracy(test_labels, test_matrix_T, DT_TFIDF, train_labels)\n",
    "print('The accuracy rate with the Rocchio Method is: ' + str(result_rocchio))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The accuracy rate with the Rocchio Method adapted for text categorization is 98%.  This is a very high accuracy rate, and compared to the results of the approaches tried earlier, seems to be on par with some of the very best results.  The highest accuracy measure recorded was 99% using a Cosine similarity measure in KNN with TFxIDF weighted training/test sets (where the value of K was 8 to 20).  Thus, it seems that the Rocchio method compares very well."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
